% \section{Segment Trees, Generally}

% Although most reference material on segment trees (or Fenwick trees)
% talks about sums of \emph{integers}, this is needlessly specific.  In
% general, all we need is a sequence of elements from
% some \emph{monoid}.  Recall that a monoid is a set $M$ together with
% an associative binary operation $\oplus : M \times M \to M$ and an
% identity element $\mempty \in M$ such that
% $m \oplus \mempty = \mempty \oplus m = m$ for all $m \in M$. We will
% continue to talk about ``sums'' of elements of a monoid $M$ even
% though the monoidal operation need not be sum-like in general (for
% example, the set of natural numbers forms a monoid under
% multiplication).  However, the ``sum'' metaphor does fail in one
% important way: unlike addition, $\oplus$ need not be commutative, that
% is, we may have $a \oplus b \neq b \oplus a$.  All the data structures
% we will discuss work perfectly well for non-commutative monoids,
% though some care is required to ensure values are combined in the
% correct order.

% Some monoids also have \emph{inverses}, that is, for each $m \in M$
% there is an element $-m \in M$ such that
% $m \oplus (-m) = (-m) \oplus m = \mempty$.  Such monoids-with-inverses
% are called \emph{groups}.  For convenience, in any group we can also
% define a ``subtraction'' operation $a \ominus b = a \oplus (-b)$.
% Although basic segment trees work with any monoid, the constructions
% we consider in the rest of the paper will generally require a group.

% Used to have a note here that said: "actually, depends on whether
% your update operation lets you set value arbitrarily (requires group
% to update cached sums!), or allows you to combine with a given
% value."  But that's not true.  To update the cached sums when we
% only have a monoid, think in terms of *rebuilding* the cached sums
% instead of *updating* them.  Indeed, if we set a leaf value to a new
% value, we don't know "by how much it changed"; but we can just throw
% away any cached sums in the path up to the root and rebuild them by
% combining values from their children.  Of course this works well for
% binary trees but not so great for schemes with buckets since we
% don't want to have to rebuild the sum of an entire bucket from
% scratch.


First, let's see that there is enough information remaining to
reconstruct the information that was discarded.  You might wish to
pause at this point and work it out for yourself: can you deduce what
values must go in the greyed-out nodes in \pref{fig:deactivate-right},
without peeking at any previous figures?

\begin{theorem}
  The value of any inactive node in a thinned segment tree over a
  group can be recovered, in $O(\lg n)$ time, using only the values of
  active nodes.
\end{theorem}
\begin{proof}
  The proof is by induction on the depth of an inactive node from its
  nearest active ancestor.  Note that every inactive node must have an
  active ancestor; if nothing else, the root of the tree remains
  active.
  \begin{itemize}
  \item In the base case, if an inactive node is the child of an
    active node, the situation looks like the diagram on the left side
    of \pref{fig:inactive-child}.
    \begin{figure}
    \begin{center}
    \begin{diagram}[width=150]
      import FenwickDiagrams
      import SegTree
      dia :: Diagram B
      dia = hsep 2
        [ t # deactivate # drawSegTree stopts
          # beneath upedge
        , t # deactivateR Inactive # drawSegTree stopts
          # beneath upedge
        ]
        where
          t = Branch "p" 1 2 (Leaf "l" 1) (Leaf "r" 2)
          iopts = (showInactiveOpts True) { nodeShape = const circleNodeShape }
          stopts = (mkSTOpts iopts) { stVSep = 0.5 }
          upedge = ((origin ~~ ((-0.5) ^& 1)) # dashingL [0.05,0.05] 0)
    \end{diagram}
    \end{center}
    \caption{An inactive node whose parent is: (L) active (R) inactive} \label{fig:inactive-child}
    \end{figure}
    In this case $p = l \oplus r$ by definition, so $r$ can be
    computed as $(-l) \oplus p$. (It is tempting to say $r = p \ominus
    l$, but note that is only correct if the group is commutative.)
  \item Otherwise, the situation looks like the right side of
    \pref{fig:inactive-child}.  Again $r = (-l) \oplus p$, but we do
    not know the value of $p$.  However, since $p$ is closer to its
    nearest active ancestor than $r$, by the induction hypothesis we
    can find an expression for $p$ using only the values of active
    nodes; substituting this into $r = (-l) \oplus p$ yields the
    desired expression for $r$.
  \end{itemize}
  As for taking logarithmic time, the inductive case shows that the
  number of operations ultimately needed to compute $r$ grows linearly
  with the depth of $r$ from its nearest active ancestor, which is
  bounded by the depth of the tree.
\end{proof}

This proof is, in fact, an algorithm, although this algorithm isn't
typically used, because it is too specialized. Simply being able to
\emph{recover} all the discarded information isn't particularly
useful; what we really want is to perform range queries and updates.

Updates are easy: as before, we only need to update nodes along the
path from the modified leaf to the root, simply skipping any inactive
nodes along the way.  However, it is less clear that we can still do
range queries in $O(\lg n)$ time.  Naively, we would need to do
$O(\lg n)$ work (using the above algorithm) to reconstruct each of the
$O(\lg n)$ nodes needed to compute a range sum, resulting in
$O((\lg n)^2)$ time.  This isn't bad, but we can do better.  The key
is to focus on \emph{prefix} sums, that is, range queries of the form
$[1,j]$.


------------------------------------------------------------
-- Proof of

During the above calculation we have also made use of the equality |clear
(n+1) . shl = shl . clear n|, which can be shown by a
simple calculation.


Now we can formally relate the ``shifting with a placeholder'' scheme
to the use of the |atLSB| function, with the following (admittedly
rather technical) lemma:

\begin{lem} \label{lem:placeholder-scheme} Let $n \geq 1$ and let |f
  :: Bits -> Bits| be a function such that
  \begin{enumerate}
  \item |(f . set (n+1)) x = (set (n+1) . f) x| for any $0 < x \leq 2^n$
  \item $|f x| < 2^{n+1}$ for any $0 < x \leq 2^n + 2^{n-1}$ as long
    as $n \geq 2$
  \end{enumerate}
  Then for all $0 < x \leq 2^n$,
  \[ |(unshift (n+1) . f . shift (n+1)) x = atLSB f x|. \]
\end{lem}
\begin{proof}
  By induction on $x$.  First, suppose |x = xs :. I|.  In that case,
  |atLSB f (xs :. I) = f (xs :. I)|, and
  \begin{sproof}
    \stmt{|(unshift (n+1) . f . ul(shift (n+1))) (xs :. I)|}
    \reason{=}{Definition of |shift|}
    \stmt{|(unshift (n+1) . f . while even shr . ul(set (n+1))) (xs :. I)|}
    \reason{=}{Definition of |set|}
    \stmt{|(unshift (n+1) . f . ul(while even shr)) (set n xs :. I)|}
    \reason{=}{|while even f y = y| on odd |y|}
    \stmt{|(unshift (n+1) . f) (ul(set n xs) :. I)|}
    \reason{=}{Definition of |set|}
    \stmt{|(unshift (n+1) . ul(f . set (n+1))) (xs :. I)|}
    \reason{=}{|f| commutes with |set (n+1)| on input $\leq 2^n$}
    \stmt{|(ul(unshift (n+1)) . set (n+1) . f) (xs :. I)|}
    \reason{=}{Definition of |unshift|}
    \stmt{|(clear (n+1) . ul(while (not . test (n+1)) shl . set (n+1)) . f) (xs :. I)|}
    \reason{=}{|not . test (n+1)| is false on output of |set (n+1)|}
    \stmt{|(ul(clear (n+1) . set (n+1)) . f) (xs :. I)|}
    \reason{=}{|clear (n+1)| and |set (n+1)| are inverse, since $|f x| < 2^{n+1}$}
    \stmt{f (xs :. I)}
  \end{sproof}
  Next, if |x = xs :. O|, then |atLSB f (xs :. O) = atLSB f xs :. O|,
  and we can proceed by a nested induction on $n$.  First, if $n = 1$,
  then $x = 2$ (the only $0 < x \leq 2^n$ that ends with a zero bit),
  and an easy calculation shows that both sides are equal to |atLSB f
  1 :. O|.  XXX verify this!!   Otherwise, if $n \geq 2$, we have  XXX working here
  \begin{sproof}
    \stmt{|(unshift (n+1) . f . ul(shift (n+1))) (xs :. O)|}
    \reason{=}{Definition of |shift|}
    \stmt{|(unshift (n+1) . f . while even shr . ul(set (n+1))) (xs :. O)|}
    \reason{=}{Definition of |set|}
    \stmt{|(unshift (n+1) . f . while even shr) (ul(set n xs :. O))|}
    \reason{=}{Definition of |while| and |even|}
    \stmt{|(ul(unshift (n+1)) . f . ul(while even shr . set n)) xs|}
    \reason{=}{Definition of |unshift| and |shift|}
    \stmt{|(clear (n+1) . ul(while (not . test (n+1)) shl) . f . shift n) xs|}
  \end{sproof}

  At this point we would like to rewrite |while (not . test (n+1))
  shl| by pulling out one iteration of |shl|.  First, note that the
  input to the |while| will be less than $2^{n+1}$ (and hence the
  |while| will iterate at least once): since $|x = xs :. O| \leq 2^n$,
  we have $|xs| \leq 2^{n-1}$ and $|shift n xs| \leq 2^n + 2^{n-1}$
  (recall that |shift n = while even shr . set n| sets the $n$th bit
  and then can only make the number smaller by doing repeated right
  shifts). Hence by assumption $|f (shift n xs)| < 2^{n+1}$.
  \begin{lem} \label{lem:shlwhile}
    For all $0 \leq x < 2^{n+1}$, \[ |(while (not . test (n+1)) shl) x = (shl
      . while (not . test n) shl) x|. \]
  \end{lem}
  We defer the proof of this lemma to later; getting back to the main
  proof we can use it to make further progress:
  \begin{sproof}
    \stmt{|(clear (n+1) . ul(while (not . test (n+1)) shl) . f . shift n) xs|}
    \reason{=}{\pref{lem:shlwhile}}
    \stmt{|(ul(clear (n+1) . shl) . while (not . test n) shl . f . shift n) xs|}
    \reason{=}{|clear (n+1) . shl = shl . clear n|}
    \stmt{|(shl . ul(clear n . while (not . test n) shl) . f . shift n) xs|}
    \reason{=}{Definition of |unshift|}
    \stmt{|(shl . unshift n . f . shift n) xs|}
    \reason{=}{Induction hypothesis}
    \stmt{|shl (atLSB f xs)|}
    \reason{=}{Definition of |shl|}
    \stmt{|atLSB f xs :. O|}
  \end{sproof}
\end{proof}

------------------------------------------------------------
-- n-smooth stuff (wrong)


% \begin{defn}
% Say a function on |Bits| is \emph{$n$-smooth} if it only examines
% up to the first $n$ bits of its input, and also leaves the input ``the
% same length''.  That is, formally, |g :: Bits -> Bits| is $n$-smooth
% if \[ |g . set m = set m . g| \] for all $m \geq n$.  Note this also
% means that if the input to $g$ is less than $2^n$, then its output
% will be as well.
% \end{defn}

% \begin{code}

% over :: Int -> (Bits -> Bits) -> Bits -> Bits
% over k f = pow shl k . f . pow shr k

% \end{code}

% \begin{thm}
%   Let |f :: Bits -> Bits| and $n \in \N$, and suppose there exists
%   some $k < n$ and $(n-k)$-smooth |g :: Bits -> Bits| such that
%   \[ |f = g . pow shr k|. \] Then for all inputs $< 2^n$, \[ |clear n . while (not . test n)
%     shl . f . set n = over k g|. \]
% \end{thm}

% \begin{proof}
%   \begin{sproof}
%     \stmt{|clear n . while (not . test n) shl . f . set n|}
%     \reason{=}{assumption}
%     \stmt{|clear n . while (not . test n) shl . g . pow shr k . set n|}
%     \reason{=}{XXX lemma}
%     \stmt{|clear n . while (not . test n) shl . g . set (n-k) . pow shr k|}
%     \reason{=}{$g$ is $(n-k)$-smooth}
%     \stmt{|clear n . while (not . test n) shl . set (n-k) . g . pow shr k|}
%     \reason{=}{Input $< 2^n$; after |shr| it is $< 2^{n-k}$; $g$
%       preserves; hence $2^{n-k}$ is biggest bit set}
%     \stmt{|clear n . pow shl k . set (n-k) . g . pow shr k|}
%     \reason{=}{XXX lemma}
%     \stmt{|clear n . set n . pow shl k . g . pow shr k|}
%     \reason{=}{XXX inverses (assuming that bit was not set in the
%       first place)}
%     \stmt{|pow shl k . g . pow shr k|}
%     \reason{=}{definition}
%     \stmt{|over k g|}
%   \end{sproof}
% \end{proof}

% XXX note |inc| is not actually $n$-smooth for any $n$ according to the
% above definition!  This is the wrong definition.  We really just need
% something about bounding the size of the output of $g$ relative to the
% size of the input.
